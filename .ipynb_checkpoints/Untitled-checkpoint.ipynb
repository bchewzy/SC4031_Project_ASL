{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70505d8b-085a-4288-9138-8cbb492daa14",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc5bf4c2-a17e-4885-93e8-38c9c954e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import string\n",
    "import skimage as ski\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d1417a6-e16e-4697-b89d-3822c71a8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import convert_to_tensor\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730bf66e-17c8-408f-9698-297df8f3f21a",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9b7957e-55a7-4344-995f-979a48c12997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    # Load image\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Resize image to (64, 64)\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    \n",
    "    # Convert image to RGB format\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "    '''\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
    "    return img\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3d049-a757-41ee-9f8f-7b9ff569f125",
   "metadata": {},
   "source": [
    "## Declare Constants/Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5bc1296-f07d-46b1-bb75-9b4073c5effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./asl_alphabet/asl_alphabet_train/\"\n",
    "TEST_DIR = \"./asl_alphabet/asl_alphabet_test/\"\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66e377f5-4e47-4cbb-83ea-aca58003d5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for folder in os.listdir(\"./\" + TRAIN_DIR):\n",
    "    labels.append(folder)\n",
    "    \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aeeada29-804a-4152-aff7-97f639593540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A1000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A1001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86995</th>\n",
       "      <td>Z</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/Z/Z995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86996</th>\n",
       "      <td>Z</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/Z/Z996.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86997</th>\n",
       "      <td>Z</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/Z/Z997.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86998</th>\n",
       "      <td>Z</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/Z/Z998.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86999</th>\n",
       "      <td>Z</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/Z/Z999.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            img\n",
       "0         A     ./asl_alphabet/asl_alphabet_train/A/A1.jpg\n",
       "1         A    ./asl_alphabet/asl_alphabet_train/A/A10.jpg\n",
       "2         A   ./asl_alphabet/asl_alphabet_train/A/A100.jpg\n",
       "3         A  ./asl_alphabet/asl_alphabet_train/A/A1000.jpg\n",
       "4         A  ./asl_alphabet/asl_alphabet_train/A/A1001.jpg\n",
       "...     ...                                            ...\n",
       "86995     Z   ./asl_alphabet/asl_alphabet_train/Z/Z995.jpg\n",
       "86996     Z   ./asl_alphabet/asl_alphabet_train/Z/Z996.jpg\n",
       "86997     Z   ./asl_alphabet/asl_alphabet_train/Z/Z997.jpg\n",
       "86998     Z   ./asl_alphabet/asl_alphabet_train/Z/Z998.jpg\n",
       "86999     Z   ./asl_alphabet/asl_alphabet_train/Z/Z999.jpg\n",
       "\n",
       "[87000 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = []\n",
    "label_list = []\n",
    "\n",
    "for label in labels:\n",
    "    label_path = os.path.join(TRAIN_DIR, label, \"*\")\n",
    "    \n",
    "    img_files = glob.glob(label_path)\n",
    "    img_files = [file.replace(\"\\\\\", \"/\") for file in img_files]\n",
    "    img_labels = [label] * len(img_files)\n",
    "\n",
    "    path_list.extend(img_files)\n",
    "    label_list.extend(img_labels)\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    \"label\": label_list,\n",
    "    \"img\": path_list\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02b187b4-2a3b-423e-b24c-0bcc2839f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset[\"img\"],\n",
    "    dataset[\"label\"],\n",
    "    test_size=0.25,\n",
    "    shuffle=True,\n",
    "    stratify=dataset[\"label\"]\n",
    ")\n",
    "\n",
    "data_train = pd.DataFrame({\n",
    "    \"label\": y_train,\n",
    "    \"img\": X_train\n",
    "})\n",
    "\n",
    "data_test = pd.DataFrame({\n",
    "    \"label\": y_test,\n",
    "    \"img\": X_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27b935cf-f11e-494e-98ac-56a81e176139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54107</th>\n",
       "      <td>Q</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/Q/Q1095.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66752</th>\n",
       "      <td>T</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/T/T1676.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A2584.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16573</th>\n",
       "      <td>E</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/E/E2414.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70876</th>\n",
       "      <td>U</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/U/U2688.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72868</th>\n",
       "      <td>V</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/V/V1780.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16776</th>\n",
       "      <td>E</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/E/E2598.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72063</th>\n",
       "      <td>V</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/V/V1055.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10316</th>\n",
       "      <td>D</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/D/D2183.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>A</td>\n",
       "      <td>./asl_alphabet/asl_alphabet_train/A/A2153.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            img\n",
       "54107     Q  ./asl_alphabet/asl_alphabet_train/Q/Q1095.jpg\n",
       "66752     T  ./asl_alphabet/asl_alphabet_train/T/T1676.jpg\n",
       "1761      A  ./asl_alphabet/asl_alphabet_train/A/A2584.jpg\n",
       "16573     E  ./asl_alphabet/asl_alphabet_train/E/E2414.jpg\n",
       "70876     U  ./asl_alphabet/asl_alphabet_train/U/U2688.jpg\n",
       "...     ...                                            ...\n",
       "72868     V  ./asl_alphabet/asl_alphabet_train/V/V1780.jpg\n",
       "16776     E  ./asl_alphabet/asl_alphabet_train/E/E2598.jpg\n",
       "72063     V  ./asl_alphabet/asl_alphabet_train/V/V1055.jpg\n",
       "10316     D  ./asl_alphabet/asl_alphabet_train/D/D2183.jpg\n",
       "1283      A  ./asl_alphabet/asl_alphabet_train/A/A2153.jpg\n",
       "\n",
       "[21750 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f2a19-8052-4b39-8e45-fdcc9a8de71d",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9884d30f-154e-438c-8949-0b71ad014089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65250 validated image filenames belonging to 29 classes.\n",
      "Found 21750 validated image filenames belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set = datagen.flow_from_dataframe(\n",
    "    data_train,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img\",\n",
    "    y_col=\"label\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    ")\n",
    "\n",
    "test_set = datagen.flow_from_dataframe(\n",
    "    data_test,\n",
    "    directory=\"./\",\n",
    "    x_col=\"img\",\n",
    "    y_col=\"label\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=1,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316c322-d014-451b-9a89-70b9212d8ed8",
   "metadata": {},
   "source": [
    "## Create Base Model: VGG16 Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ede4115-fe19-4305-b6c0-3e2c5261707c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95001695-1fdd-40e4-a141-0fc5bde8b25e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 29)                14877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16041309 (61.19 MB)\n",
      "Trainable params: 1326621 (5.06 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "393dc618-1612-4169-a2c5-c2a100c91346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1020/1020 [==============================] - ETA: 0s - loss: 1.0325 - accuracy: 0.6742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020/1020 [==============================] - 1355s 1s/step - loss: 1.0325 - accuracy: 0.6742 - val_loss: 0.2221 - val_accuracy: 0.9265\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 1338s 1s/step - loss: 0.3676 - accuracy: 0.8749 - val_loss: 0.1075 - val_accuracy: 0.9686\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 1298s 1s/step - loss: 0.2699 - accuracy: 0.9078 - val_loss: 0.1099 - val_accuracy: 0.9643\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 1325s 1s/step - loss: 0.2375 - accuracy: 0.9181 - val_loss: 0.0614 - val_accuracy: 0.9803\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 1311s 1s/step - loss: 0.2068 - accuracy: 0.9301 - val_loss: 0.0671 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 1329s 1s/step - loss: 0.1878 - accuracy: 0.9363 - val_loss: 0.0455 - val_accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 1384s 1s/step - loss: 0.1833 - accuracy: 0.9387 - val_loss: 0.0404 - val_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 1364s 1s/step - loss: 0.1682 - accuracy: 0.9439 - val_loss: 0.0325 - val_accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 1342s 1s/step - loss: 0.1464 - accuracy: 0.9501 - val_loss: 0.0292 - val_accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 1326s 1s/step - loss: 0.1454 - accuracy: 0.9517 - val_loss: 0.0308 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_2' (type Functional).\n    \n    Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n    \n    Call arguments received by layer 'model_2' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 20\u001b[0m\n\u001b[0;32m      3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m     train_set,\n\u001b[0;32m      5\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint]\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# history = model.fit(\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     X_test_np,\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#     y_test_np,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     callbacks=[checkpoint]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: %.2f%\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebi71l8zu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1850, in test_step\n        y_pred = self(x, training=False)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_2' (type Functional).\n    \n    Input 0 of layer \"block1_conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 1)\n    \n    Call arguments received by layer 'model_2' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('ASL_VGG16_CP.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=10,\n",
    "    validation_data=test_set,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_test_np,\n",
    "#     y_test_np,\n",
    "#     epochs=10,\n",
    "#     validation_data=(X_test_np, y_test_np),\n",
    "#     verbose=1,\n",
    "#     callbacks=[checkpoint]\n",
    "# )\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: %.2f%', score[1]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c792d1f5-ae04-42cf-b5bc-a57e191bf780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21750/21750 [==============================] - 586s 27ms/step - loss: 0.0308 - accuracy: 0.9914\n",
      "Test Accuracy: %.2f% 99.13563132286072\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_set)\n",
    "print(f'Test Accuracy: %.2f%', score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a533f8ae-6ac9-434b-ab95-e35bcd13bf4d",
   "metadata": {},
   "source": [
    "## Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "15f414c8-cfad-4326-a40a-2042ac015415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "[[2.4786295e-10 2.7361728e-13 9.0594746e-08 7.4084276e-08 2.3351093e-07\n",
      "  2.1080603e-04 2.6959020e-01 6.6010766e-09 1.0389356e-03 7.0323671e-07\n",
      "  3.6638859e-08 3.7846190e-01 5.3783261e-10 5.8701988e-03 3.3428599e-08\n",
      "  1.2140845e-08 1.9804873e-09 7.8596740e-10 1.8535360e-05 1.0561497e-04\n",
      "  5.3805174e-08 1.7133310e-03 5.0877698e-09 3.4085488e-01 2.0587067e-03\n",
      "  5.2802898e-06 4.6625368e-12 4.9890013e-13 7.0365204e-05]]\n"
     ]
    }
   ],
   "source": [
    "# test_imgs = [\"./test/test.jpg\"]\n",
    "test_imgs = [\"./asl_alphabet/asl_alphabet_test/A_test.jpg\", \"./asl_alphabet/asl_alphabet_test/B_test.jpg\"]\n",
    "\n",
    "preprocessed_images = [preprocess_image(image_path) for image_path in test_imgs]\n",
    "\n",
    "#preprocessed_img = preprocess_image(\"./test/test.jpg\")\n",
    "\n",
    "# Convert preprocessed images to a numpy array\n",
    "test_img_np = np.array(preprocessed_img)\n",
    "\n",
    "# Predict probabilities for the input data\n",
    "predictions = model.predict(test_img_np)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89f65147-a3e0-4dc4-8cfa-e174a691879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n"
     ]
    }
   ],
   "source": [
    "# Get the index of the class with the highest probability for each prediction\n",
    "predicted_class_indices = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Assuming you have a list of class labels\n",
    "class_labels = ['class1', 'class2', ...]\n",
    "\n",
    "# Map the predicted indices to class labels\n",
    "predicted_labels = [label_list[idx] for idx in predicted_class_indices]\n",
    "\n",
    "# Print the predicted labels\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032042f8-bdaf-413f-baa6-9d860e196d3d",
   "metadata": {},
   "source": [
    "### long pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f6ede7-9f4d-4bd3-b730-678023d0889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:22<00:00, 134.81it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 150.52it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 151.39it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 151.59it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 152.94it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 152.88it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 151.65it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 151.39it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 151.19it/s]\n",
      "100%|██████████| 3000/3000 [00:19<00:00, 150.63it/s]\n",
      "100%|██████████| 3000/3000 [00:20<00:00, 148.74it/s]\n",
      "100%|██████████| 3000/3000 [00:20<00:00, 149.22it/s]\n",
      "100%|██████████| 3000/3000 [00:21<00:00, 137.09it/s]\n",
      "100%|██████████| 3000/3000 [00:21<00:00, 141.47it/s]\n",
      "100%|██████████| 3000/3000 [00:21<00:00, 141.45it/s]\n",
      "100%|██████████| 3000/3000 [00:23<00:00, 127.15it/s]\n",
      "100%|██████████| 3000/3000 [00:23<00:00, 129.35it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 133.57it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 131.29it/s]\n",
      "100%|██████████| 3000/3000 [00:23<00:00, 129.68it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 134.31it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 132.81it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 134.37it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 133.50it/s]\n",
      "100%|██████████| 3000/3000 [00:22<00:00, 130.58it/s]\n",
      "100%|██████████| 3000/3000 [00:23<00:00, 129.90it/s]\n",
      "100%|██████████| 3000/3000 [00:23<00:00, 125.30it/s]\n",
      "100%|██████████| 3000/3000 [00:21<00:00, 139.53it/s]\n",
      "100%|██████████| 3000/3000 [00:21<00:00, 141.84it/s]\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for label in labels:\n",
    "    label_dir = os.listdir(TRAIN_DIR + label)\n",
    "    \n",
    "    #for img_file in label_dir:\n",
    "    for img_file in tqdm(os.listdir(TRAIN_DIR + label)):\n",
    "        img = ski.io.imread(TRAIN_DIR + label + \"/\" + img_file)\n",
    "        \n",
    "        if img is not None:\n",
    "            img = ski.transform.resize(img, (IMG_SIZE, IMG_SIZE, 3))\n",
    "            image_list.append(np.asarray(img))\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2376a8d-0807-48db-a194-d7408a97cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_np = np.asarray(label_list)\n",
    "image_list_np = tqdm(np.asarray(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6340af80-8a31-4f76-b4bb-e2237e1a959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({\n",
    "    \"label\": label_list,\n",
    "    \"image\": image_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0599f14d-3360-4960-b3a6-e560c3e0928c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>[[[0.04664231280990306, 0.027383431080760762, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>[[[0.04449896587220301, 0.02742362708037281, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>[[[0.04490480469801815, 0.02917625551275024, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>[[[0.0456116105159629, 0.02930081199990124, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>[[[0.07728538297750479, 0.06234614464730623, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86995</th>\n",
       "      <td>Z</td>\n",
       "      <td>[[[0.06069904531082118, 0.06507387745854654, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86996</th>\n",
       "      <td>Z</td>\n",
       "      <td>[[[0.05967995042610821, 0.06490213078344755, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86997</th>\n",
       "      <td>Z</td>\n",
       "      <td>[[[0.060874963702650754, 0.06307113191584232, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86998</th>\n",
       "      <td>Z</td>\n",
       "      <td>[[[0.06040922614906784, 0.06706864183900617, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86999</th>\n",
       "      <td>Z</td>\n",
       "      <td>[[[0.05966835869112738, 0.06420354234364416, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              image\n",
       "0         A  [[[0.04664231280990306, 0.027383431080760762, ...\n",
       "1         A  [[[0.04449896587220301, 0.02742362708037281, 0...\n",
       "2         A  [[[0.04490480469801815, 0.02917625551275024, 0...\n",
       "3         A  [[[0.0456116105159629, 0.02930081199990124, 0....\n",
       "4         A  [[[0.07728538297750479, 0.06234614464730623, 0...\n",
       "...     ...                                                ...\n",
       "86995     Z  [[[0.06069904531082118, 0.06507387745854654, 0...\n",
       "86996     Z  [[[0.05967995042610821, 0.06490213078344755, 0...\n",
       "86997     Z  [[[0.060874963702650754, 0.06307113191584232, ...\n",
       "86998     Z  [[[0.06040922614906784, 0.06706864183900617, 0...\n",
       "86999     Z  [[[0.05966835869112738, 0.06420354234364416, 0...\n",
       "\n",
       "[87000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7012cf-129d-461b-bba9-88000fdbf433",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0958de98-9473-4c46-b093-3d9ba37cd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset[\"image\"],\n",
    "    dataset[\"label\"],\n",
    "    test_size=0.25,\n",
    "    shuffle=True,\n",
    "    stratify=dataset[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c4fb5-f86e-433a-b35f-f73220369297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65250/65250 [00:00<00:00, 786585.70it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_np = np.array(list(tqdm(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b893aee-4830-425c-8e60-dcef7658a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65250/65250 [00:00<00:00, 365158.11it/s]\n"
     ]
    }
   ],
   "source": [
    "y_train_np = np.array(list(tqdm(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b484b7e-7149-482a-9fcc-d119319e429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21750/21750 [00:00<00:00, 305383.90it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_np = np.array(list(tqdm(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1a899ae-a5d2-4567-8f6c-1837adc25b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21750/21750 [00:00<00:00, 1144618.72it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_test_np = np.asarray(list(tqdm(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4a2ac-048d-41fd-9ced-9fc7562780e4",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c659241-c0ad-4fe6-ae4a-7bbdea62d480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_np = np.asarray(X_train)\n",
    "y_train_np = np.asarray(y_train)\n",
    "X_test_np = np.asarray(X_test)\n",
    "y_test_np = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ec5dfe5-738f-4c2e-b49e-bd271a54a816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d63cea13-72ac-44be-9986-6cf0b762ea47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65709    [[[0.051187913608321714, 0.061393378171680515,...\n",
       "20314    [[[0.05092968757820715, 0.021522621170152592, ...\n",
       "43359    [[[0.018309688043798695, 0.014140365062057706,...\n",
       "64054    [[[0.05865932062836549, 0.05291342913691875, 0...\n",
       "37659    [[[0.017578115008094388, 0.012048067669890375,...\n",
       "                               ...                        \n",
       "68562    [[[0.05654434593646645, 0.06272258395599282, 0...\n",
       "48344    [[[0.06741198777804495, 0.05387703677197149, 0...\n",
       "63652    [[[0.056499463215847, 0.04932604032159516, 0.8...\n",
       "53903    [[[0.053237481380855455, 0.05595629035490712, ...\n",
       "69265    [[[0.061315121386406594, 0.05000016273446092, ...\n",
       "Name: image, Length: 65250, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bd10886-747a-49fd-a5d9-e2d685ce7f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 29) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# history = model.fit(\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     X_train,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     y_train,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# X_test_tf = convert_to_tensor(X_test)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# y_test_tf = convert_to_tensor(y_test)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_np\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileagfkj9sz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"D:\\Anaconda3\\envs\\sc4031\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 29) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=10,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     verbose=1,\n",
    "#     callbacks=[checkpoint]\n",
    "# )\n",
    "\n",
    "# X_train_tf = convert_to_tensor(X_train)\n",
    "# y_train_tf = convert_to_tensor(y_train)\n",
    "# X_test_tf = convert_to_tensor(X_test)\n",
    "# y_test_tf = convert_to_tensor(y_test)\n",
    "\n",
    "history = model.fit(\n",
    "    X_test_np,\n",
    "    y_test_np,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test_np, y_test_np),\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(f'Test Accuracy: %.2f%', score[1]*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
